<div align="center">
    <h1>
    FireRedTTS-2
    </h1>
    <p>
    Official PyTorch code for <br>
    <b><em>FireRedTTS-2: Towards Long Conversational Speech Generation for Podcast and Chatbot</em></b>
    </p>
    <p>
    <!-- <img src="assets/XiaoHongShu_Logo.png" alt="Institution 4" style="width: 102px; height: 48px;"> -->
    <img src="assets/FireRedTTS_Logo.png" alt="FireRedTTS_Logo" style="width: 248px; height: 68px;">
    </p>
    <p>
    </p>
    <a href="https://arxiv.org/abs/2509.02020"><img src="https://img.shields.io/badge/Paper-ArXiv-red" alt="technical report"></a>
    <a href="https://fireredteam.github.io/demos/firered_tts_2/"><img src="https://img.shields.io/badge/Demo-Page-lightgrey" alt="version"></a>
    <a href="https://huggingface.co/FireRedTeam/FireRedTTS2"><img src="https://img.shields.io/badge/Hugging%20Face-Model%20Page-yellow" alt="HF-model"></a>
    <a href="https://github.com/FireRedTeam/FireRedTTS"><img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg" alt="Apache-2.0"></a>
</div>

## Overview

FireRedTTSâ€‘2 is a long-form streaming TTS system for **multi-speaker dialogue generation**, delivering stable, natural speech with reliable speaker switching and context-aware prosody.

## HighlightğŸ”¥

- **Long Conversational Speech Generation**: It currently supports 3 minutes dialogues with 4 speakers and can be easily scaled to longer conversations
with more speakers by extending training corpus.
- **Multilingual Support**: It supports multiple languages including English, Chinese, Japanese, Korean, French, German, and Russian. Support zero-shot voice cloning for cross-lingual and code-switching scenarios.
- **Ultra-Low Latency**: Building on the new **12.5Hz streaming** speech tokenizer, we employ a dual-transformer architecture that operates on a textâ€“speech interleaved sequence, enabling flexible sentence-bysentence generation and reducing first-packet latencyï¼ŒSpecifically, on an L20 GPU, our first-packet latency as low as 140ms while maintaining high-quality audio output.
- **Strong Stability**ï¼šOur model achieves high similarity and low WER/CER in both monologue and dialogue tests.
- **Random Timbre Generation**:Useful for creating ASR/speech interaction data.

## Demo Examples

**Random Timbre Generation & Multilingual Support**
<div align="center">

<https://github.com/user-attachments/assets/804e9e67-fb15-4557-9715-43cd46a1b3e8>

</div>

**Zero-Shot Podcast Generation**
<div align="center">

<https://github.com/user-attachments/assets/e68b1b7e-1329-47bb-a16f-8589cf227579>

</div>

**Speaker-Specific Finetuned Podcast Generation**

âš ï¸ Speaker voices: hosts "è‚¥æ°" and "æƒ å­" from the podcast "è‚¥è¯è¿ç¯‡". Use without authorization is forbidden.

âš ï¸ å£°éŸ³æ¥æºï¼šæ’­å®¢ "è‚¥è¯è¿ç¯‡" ä¸»æ’­ "è‚¥æ°" å’Œ "æƒ å­"ï¼Œæœªç»æˆæƒä¸èƒ½ä½¿ç”¨ã€‚
<div align="center">

<https://github.com/user-attachments/assets/21f626cb-eaf4-4f5c-920c-3d5d4c8cfa8b>

</div>

For more examples, see [demo page](https://fireredteam.github.io/demos/firered_tts_2/).

## News

- [2025/10/26] ğŸ”¥ **We have released comprehensive [fine-tuning](<https://github.com/FireRedTeam/FireRedTTS2/blob/main/bin/finetune_example/tutorial.md>) code and tutorials (based on the LJSpeech dataset).** You can easily adapt this foundation to fine-tune models for multilingual or even conversational datasets. With conversational data, you can achieve podcast generation results comparable to our demo showcase.
- [2025/10/11] **We now support streaming dialogue generation.**
- [2025/09/28] **Supports bf16 inference, reducing VRAM usage from 14GB to 9GB and enabling consumer-grade GPU deployment.**
- [2025/09/12] We have added a UI tool to the dialogue generation.
- [2025/09/08] We release the [pre-trained checkpoints](https://huggingface.co/FireRedTeam/FireRedTTS2) and inference code.
- [2025/09/02] We release the [technical report](https://arxiv.org/abs/2509.02020) and [demo page](https://fireredteam.github.io/demos/firered_tts_2/)

## Roadmap

- [x] 2025/09
  - [x] Release the pre-trained checkpoints and inference code.
  - [x] Add web UI tool.

- [ ] 2025/10
  - [ ] Release a base model with enhanced multilingual support.
  - [x] **Provide fine-tuning code & tutorial for specific dialogue/multilingual data.**
  - [ ] **End-to-end text-to-podcast pipeline.**

## Install & Model Download

### Clone and install

- **Clone the repo**

    ``` sh
    git clone https://github.com/FireRedTeam/FireRedTTS2.git
    cd FireRedTTS2
    ```

- **Create env**:

    Setup environment with Conda:

    ``` sh
    conda create --name fireredtts2 python==3.11
    conda activate fireredtts2

    # Step 1. PyTorch Installation (if required)
    pip install torch==2.7.1 torchvision==0.22.1 torchaudio==2.7.1 --index-url https://download.pytorch.org/whl/cu126

    # Step 2. Install Dependencies
    pip install -e .
    pip install -r requirements.txt
    ```

    or use Docker:

    ``` sh
    # Build docker image
    docker build -t fireredtts2:v1.0 docker
    
    # Launch docker container
    docker run -v=${PWD}:/workspace/FireRedTTS2 --ipc=host --net=host --gpus=all -it fireredtts2:v1.0 bash
    ```

- **Model download**

    ```sh
    git lfs install
    git clone https://huggingface.co/FireRedTeam/FireRedTTS2 pretrained_models/FireRedTTS2
    ```

## Basic Usage

**Dialogue Generation with Web UI**

Generate dialogue through an easy-to-use web interface that supports both voice cloning and randomized voices.

```sh
python gradio_demo.py --pretrained-dir "./pretrained_models/FireRedTTS2"
```

<div align="center">

<p>
<img src="assets/gradio.png" alt="FireRedTTS_Logo" style="width: 997px; height: 515px;">
</p>

</div>

**Dialogue Generation**

```python
import os
import sys
import torch
import torchaudio
from fireredtts2.fireredtts2 import FireRedTTS2

device = "cuda"

fireredtts2 = FireRedTTS2(
    pretrained_dir="./pretrained_models/FireRedTTS2",
    gen_type="dialogue",
    device=device,
)

text_list = [
    "[S1]é‚£å¯èƒ½è¯´å¯¹å¯¹ï¼Œæ²¡æœ‰å»è¿‡ç¾å›½æ¥è¯´å»å»çœ‹åˆ°ç¾å›½çº¿ä¸‹ã€‚å·´æ–¯æ›¼ä¹Ÿå¥½ï¼Œæ²ƒå°”ç›ä¹Ÿå¥½ï¼Œä»–ä»¬çº¿ä¸‹ä¸ç®¡è¯´ï¼Œå› ä¸ºæ·±åœ³å‡ºå»çš„è¿˜æ˜¯ç”µå­å‘¨è¾¹çš„ä¼šè¡¨è¾¾ï¼Œä¼šå‘ç°å“‡å¯¹è¿™ä¸ªä»·æ ¼çœŸçš„æ˜¯å¾ˆé«˜å‘€ã€‚éƒ½æ˜¯å–ä¸‰åäº”ç¾é‡‘ã€å››åç¾é‡‘ï¼Œç”šè‡³ä¸€ä¸ªæ‰‹æœºå£³ï¼Œå°±æ˜¯äºŒåäº”ç¾é‡‘å¼€ã€‚",
    "[S2]å¯¹ï¼Œæ²¡é”™ï¼Œæˆ‘æ¯æ¬¡éƒ½è§‰å¾—ä¸ä¸å¯æ€è®®ã€‚æˆ‘ä»€ä¹ˆäººä¼šä¹°ä¸‰äº”åç¾é‡‘çš„æ‰‹æœºå£³ï¼Ÿä½†æ˜¯å…¶å®åœ¨åœ¨é‚£ä¸ªtargetå•Šï¼Œå°±å¡”å‰ç‰¹è¿™ç§è¶…çº§å¸‚åœºï¼Œå¤§å®¶éƒ½æ˜¯è¿™æ ·çš„ï¼Œå®šä»·ä¹Ÿå¾ˆå¤šäººä¹°ã€‚",
    "[S1]å¯¹å¯¹ï¼Œé‚£è¿™æ ·æˆ‘ä»¬å†å»çœ‹è¯´äºšé©¬é€Šä¸Šé¢å–å–å–æ‰‹æœºå£³ä¹Ÿå¥½å•Šï¼Œè´´è†œä¹Ÿå¥½ï¼Œè¿˜åŒ…æ‹¬è¯´è½¦çª—ä¹Ÿå¥½ï¼Œå„ç§çº¿æä¹Ÿå¥½ï¼Œå¤§æ¦‚å°±æ˜¯ä¸ƒå—ä¹ä¹æˆ–è€…è¯´å•Šå…«å—ä¹ä¹ï¼Œè¿™ä¸ªä»·æ ¼æ‰æ˜¯å–çš„æœ€å¤šçš„å•Šã€‚å› ä¸ºäºšé©¬é€Šçš„æ¸¸æˆè§„åˆ™é™å®šçš„ã€‚å¦‚æœè¯´ä½ å–ä¸ƒå—ä¹ä¹ä»¥ä¸‹ï¼Œé‚£ä½ åŸºæœ¬ä¸Šæ˜¯ä¸èµšé’±çš„ã€‚",
    "[S2]é‚£æ¯”å¦‚è¯´å‘ƒé™¤äº†è¿™ä¸ªå¯èƒ½å»åˆ°æµ·å¤–è¿™ä¸ªè°ƒæŸ¥ï¼Œç„¶åè¿™ä¸ªè°ƒç ”è€ƒå¯Ÿé‚£è‚¯å®šæ˜¯æœ€ç›´æ¥çš„äº†ã€‚é‚£å¹³æ—¶æˆ‘çŸ¥é“ä½ æ˜¯åˆšæ‰å»ºç«‹äº†ä¸€ä¸ªè¿™ä¸ªå«åšå‘ƒreançš„è¿™æ ·çš„ä¸€ä¸ªä¸€ä¸ªæ’­å®¢ï¼Œå®ƒæ˜¯ä¸€ä¸ªè‹±æ–‡çš„ã€‚ç„¶åå¹³æ—¶ä½ è¿˜å¬ä¸€äº›ä»€ä¹ˆæ ·çš„ä¸œè¥¿ï¼Œæˆ–è€…æ˜¯ä»å“ªé‡Œè·å–ä¸€äº›è¿™ä¸ªæµ·å¤–å¸‚åœºçš„ä¸€äº›ä¿¡æ¯å‘¢ï¼Ÿ",
    "[S1]å—¯ï¼Œå› ä¸ºåšåšäºšé©¬é€Šçš„è¯å‘¢ï¼Œæˆ‘ä»¬ä¼šå…³æ³¨å¾ˆå¤šè¡Œä¸šå†…çš„ä¸œè¥¿ã€‚å°±æ¯”å¦‚è¯´è¡Œä¸šæœ‰ä»€ä¹ˆæ ·äºšé©¬é€Šæœ‰ä»€ä¹ˆæ ·æ–°çš„æ¸¸æˆè§„åˆ™å‘€ã€‚å‘ƒï¼Œç‰©æµçš„ä»·æ ¼æœ‰æ²¡æœ‰æ³¢åŠ¨å‘€ï¼ŒåŒ…æ‹¬è¯´æœ‰æ²¡æœ‰ä»€ä¹ˆæ–°çš„è¯„è®ºçš„æ”¿ç­–å‘€ï¼Œå¹¿å‘Šæœ‰ä»€ä¹ˆæ–°çš„æ‰“æ³•å‘€ï¼Ÿé‚£è¿™äº›æˆ‘ä»¬ä¼šä¼šå…³å…³æ³¨å¾ˆå¤šè¡Œä¸šå†…éƒ¨çš„å¾®ä¿¡å…¬ä¼—å·å‘€ï¼Œè¿˜åŒ…æ‹¬å»å»æŸ¥ä¸€äº›çŸ¥ä¹ä¸“æ çš„æ–‡ç« å‘€ï¼Œä»¥åŠè¯´æˆ‘ä»¬å‘¨è¾¹æœ‰å¾ˆå¤šåŒè¡Œã€‚é‚£æˆ‘ä»¬ç»å¸¸ä¼šååœ¨ä¸€èµ·èŠå¤©ï¼Œçœ‹çœ‹ä¿¡æ¯æœ‰ä»€ä¹ˆå…±äº«ã€‚é‚£è¿™ä¸ªæ˜¯å…³æ³¨å†…å†…çš„ä¸€ä¸ªæ–¹å¼ã€‚",
]
prompt_wav_list = [
    "examples/chat_prompt/zh/S1.flac",
    "examples/chat_prompt/zh/S2.flac",
]

prompt_text_list = [
    "[S1]å•Šï¼Œå¯èƒ½è¯´æ›´é€‚åˆç¾å›½å¸‚åœºåº”è¯¥æ˜¯ä»€ä¹ˆæ ·å­ã€‚é‚£è¿™è¿™ä¸ªå¯èƒ½è¯´å½“ç„¶å¦‚æœè¯´æœ‰æœ‰æœºä¼šèƒ½äº²èº«çš„å»è€ƒå¯Ÿå»äº†è§£ä¸€ä¸‹ï¼Œé‚£å½“ç„¶æ˜¯æœ‰æ›´å¥½çš„å¸®åŠ©ã€‚",
    "[S2]æ¯”å¦‚å…·ä½“ä¸€ç‚¹çš„ï¼Œä»–è§‰å¾—æœ€å¤§çš„ä¸€ä¸ªè·Ÿä»–é¢„æƒ³çš„ä¸ä¸€æ ·çš„æ˜¯åœ¨ä»€ä¹ˆåœ°æ–¹ã€‚",
]

all_audio = fireredtts2.generate_dialogue(
    text_list=text_list,
    prompt_wav_list=prompt_wav_list,
    prompt_text_list=prompt_text_list,
    temperature=0.9,
    topk=30,
)
torchaudio.save("chat_clone.wav", all_audio, 24000)
```

**Dialogue Generation (Sreaming)**

**NOTE:** Each audio chunk is 0.08 seconds, except the first (a little shorter) and last (a little longer).

```python
import torch
import torchaudio
from fireredtts2.fireredtts2 import FireRedTTS2_Stream

device = "cuda"

fireredtts2 = FireRedTTS2_Stream(
    pretrained_dir="./pretrained_models",
    gen_type="dialogue",
    device=device,
)

text_list = [
    "[S1]é‚£å¯èƒ½è¯´å¯¹å¯¹ï¼Œæ²¡æœ‰å»è¿‡ç¾å›½æ¥è¯´å»å»çœ‹åˆ°ç¾å›½çº¿ä¸‹ã€‚å·´æ–¯æ›¼ä¹Ÿå¥½ï¼Œæ²ƒå°”ç›ä¹Ÿå¥½ï¼Œä»–ä»¬çº¿ä¸‹ä¸ç®¡è¯´ï¼Œå› ä¸ºæ·±åœ³å‡ºå»çš„è¿˜æ˜¯ç”µå­å‘¨è¾¹çš„ä¼šè¡¨è¾¾ï¼Œä¼šå‘ç°å“‡å¯¹è¿™ä¸ªä»·æ ¼çœŸçš„æ˜¯å¾ˆé«˜å‘€ã€‚éƒ½æ˜¯å–ä¸‰åäº”ç¾é‡‘ã€å››åç¾é‡‘ï¼Œç”šè‡³ä¸€ä¸ªæ‰‹æœºå£³ï¼Œå°±æ˜¯äºŒåäº”ç¾é‡‘å¼€ã€‚",
    "[S2]å¯¹ï¼Œæ²¡é”™ï¼Œæˆ‘æ¯æ¬¡éƒ½è§‰å¾—ä¸ä¸å¯æ€è®®ã€‚æˆ‘ä»€ä¹ˆäººä¼šä¹°ä¸‰äº”åç¾é‡‘çš„æ‰‹æœºå£³ï¼Ÿä½†æ˜¯å…¶å®åœ¨åœ¨é‚£ä¸ªtargetå•Šï¼Œå°±å¡”å‰ç‰¹è¿™ç§è¶…çº§å¸‚åœºï¼Œå¤§å®¶éƒ½æ˜¯è¿™æ ·çš„ï¼Œå®šä»·ä¹Ÿå¾ˆå¤šäººä¹°ã€‚",
    "[S1]å¯¹å¯¹ï¼Œé‚£è¿™æ ·æˆ‘ä»¬å†å»çœ‹è¯´äºšé©¬é€Šä¸Šé¢å–å–å–æ‰‹æœºå£³ä¹Ÿå¥½å•Šï¼Œè´´è†œä¹Ÿå¥½ï¼Œè¿˜åŒ…æ‹¬è¯´è½¦çª—ä¹Ÿå¥½ï¼Œå„ç§çº¿æä¹Ÿå¥½ï¼Œå¤§æ¦‚å°±æ˜¯ä¸ƒå—ä¹ä¹æˆ–è€…è¯´å•Šå…«å—ä¹ä¹ï¼Œè¿™ä¸ªä»·æ ¼æ‰æ˜¯å–çš„æœ€å¤šçš„å•Šã€‚å› ä¸ºäºšé©¬é€Šçš„æ¸¸æˆè§„åˆ™é™å®šçš„ã€‚å¦‚æœè¯´ä½ å–ä¸ƒå—ä¹ä¹ä»¥ä¸‹ï¼Œé‚£ä½ åŸºæœ¬ä¸Šæ˜¯ä¸èµšé’±çš„ã€‚",
    "[S2]é‚£æ¯”å¦‚è¯´å‘ƒé™¤äº†è¿™ä¸ªå¯èƒ½å»åˆ°æµ·å¤–è¿™ä¸ªè°ƒæŸ¥ï¼Œç„¶åè¿™ä¸ªè°ƒç ”è€ƒå¯Ÿé‚£è‚¯å®šæ˜¯æœ€ç›´æ¥çš„äº†ã€‚é‚£å¹³æ—¶æˆ‘çŸ¥é“ä½ æ˜¯åˆšæ‰å»ºç«‹äº†ä¸€ä¸ªè¿™ä¸ªå«åšå‘ƒreançš„è¿™æ ·çš„ä¸€ä¸ªä¸€ä¸ªæ’­å®¢ï¼Œå®ƒæ˜¯ä¸€ä¸ªè‹±æ–‡çš„ã€‚ç„¶åå¹³æ—¶ä½ è¿˜å¬ä¸€äº›ä»€ä¹ˆæ ·çš„ä¸œè¥¿ï¼Œæˆ–è€…æ˜¯ä»å“ªé‡Œè·å–ä¸€äº›è¿™ä¸ªæµ·å¤–å¸‚åœºçš„ä¸€äº›ä¿¡æ¯å‘¢ï¼Ÿ",
    "[S1]å—¯ï¼Œå› ä¸ºåšåšäºšé©¬é€Šçš„è¯å‘¢ï¼Œæˆ‘ä»¬ä¼šå…³æ³¨å¾ˆå¤šè¡Œä¸šå†…çš„ä¸œè¥¿ã€‚å°±æ¯”å¦‚è¯´è¡Œä¸šæœ‰ä»€ä¹ˆæ ·äºšé©¬é€Šæœ‰ä»€ä¹ˆæ ·æ–°çš„æ¸¸æˆè§„åˆ™å‘€ã€‚å‘ƒï¼Œç‰©æµçš„ä»·æ ¼æœ‰æ²¡æœ‰æ³¢åŠ¨å‘€ï¼ŒåŒ…æ‹¬è¯´æœ‰æ²¡æœ‰ä»€ä¹ˆæ–°çš„è¯„è®ºçš„æ”¿ç­–å‘€ï¼Œå¹¿å‘Šæœ‰ä»€ä¹ˆæ–°çš„æ‰“æ³•å‘€ï¼Ÿé‚£è¿™äº›æˆ‘ä»¬ä¼šä¼šå…³å…³æ³¨å¾ˆå¤šè¡Œä¸šå†…éƒ¨çš„å¾®ä¿¡å…¬ä¼—å·å‘€ï¼Œè¿˜åŒ…æ‹¬å»å»æŸ¥ä¸€äº›çŸ¥ä¹ä¸“æ çš„æ–‡ç« å‘€ï¼Œä»¥åŠè¯´æˆ‘ä»¬å‘¨è¾¹æœ‰å¾ˆå¤šåŒè¡Œã€‚é‚£æˆ‘ä»¬ç»å¸¸ä¼šååœ¨ä¸€èµ·èŠå¤©ï¼Œçœ‹çœ‹ä¿¡æ¯æœ‰ä»€ä¹ˆå…±äº«ã€‚é‚£è¿™ä¸ªæ˜¯å…³æ³¨å†…å†…çš„ä¸€ä¸ªæ–¹å¼ã€‚",
]
prompt_wav_list = [
    "examples/chat_prompt/zh/S1.flac",
    "examples/chat_prompt/zh/S2.flac",
]

prompt_text_list = [
    "[S1]å•Šï¼Œå¯èƒ½è¯´æ›´é€‚åˆç¾å›½å¸‚åœºåº”è¯¥æ˜¯ä»€ä¹ˆæ ·å­ã€‚é‚£è¿™è¿™ä¸ªå¯èƒ½è¯´å½“ç„¶å¦‚æœè¯´æœ‰æœ‰æœºä¼šèƒ½äº²èº«çš„å»è€ƒå¯Ÿå»äº†è§£ä¸€ä¸‹ï¼Œé‚£å½“ç„¶æ˜¯æœ‰æ›´å¥½çš„å¸®åŠ©ã€‚",
    "[S2]æ¯”å¦‚å…·ä½“ä¸€ç‚¹çš„ï¼Œä»–è§‰å¾—æœ€å¤§çš„ä¸€ä¸ªè·Ÿä»–é¢„æƒ³çš„ä¸ä¸€æ ·çš„æ˜¯åœ¨ä»€ä¹ˆåœ°æ–¹ã€‚",
]

all_audio = []
audio_generator = fireredtts2.generate_dialogue(
    text_list=text_list,
    prompt_wav_list=prompt_wav_list,
    prompt_text_list=prompt_text_list,
    temperature=0.9,
    topk=30,
)
for audio_chunk in audio_generator:
    all_audio.append(audio_chunk)
all_audio = torch.cat(all_audio, dim=1)

torchaudio.save("chat_clone_stream.wav", all_audio, 24000)
```

**Monologue Generation**

```python
import os
import sys
import torch
import torchaudio
from fireredtts2.fireredtts2 import FireRedTTS2

device = "cuda"
lines = [
    "Hello everyone, welcome to our newly launched FireRedTTS2. It supports multiple languages including English, Chinese, Japanese, Korean, French, German, and Russian. Additionally, this TTS model features long-context dialogue generation capabilities.",
    "å¦‚æœä½ åŒå€¦äº†åƒç¯‡ä¸€å¾‹çš„AIéŸ³è‰²ï¼Œä¸æ»¡æ„äºå…¶ä»–æ¨¡å‹è¯­è¨€æ”¯æŒä¸å¤Ÿä¸°å¯Œï¼Œé‚£ä¹ˆæœ¬é¡¹ç›®å°†ä¼šæˆä¸ºä½ ç»ä½³çš„å·¥å…·ã€‚",
    "ãƒ©ãƒ³ãƒ€ãƒ ãªè©±è€…ã¨è¨€èªã‚’é¸æŠã—ã¦åˆæˆã§ãã¾ã™",
    "ì´ëŠ” ë§ì€ ì¸ê³µì§€ëŠ¥ ì‹œìŠ¤í…œì— ìœ ìš©í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì œê°€ ë‹¤ì–‘í•œ ìŒì„± ë°ì´í„°ë¥¼ ëŒ€ëŸ‰ìœ¼ë¡œ ìƒì„±í•´ ì—¬ëŸ¬ë¶„ì˜ ASR ëª¨ë¸ì´ë‚˜ ëŒ€í™” ëª¨ë¸ì— í’ë¶€í•œ ë°ì´í„°ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    "J'Ã©volue constamment et j'espÃ¨re pouvoir parler davantage de langues avec plus d'aisance Ã  l'avenir.",
]

fireredtts2 = FireRedTTS2(
    pretrained_dir="./pretrained_models/FireRedTTS2",
    gen_type="monologue",
    device=device,
)

# random speaker
for i in range(len(lines)):
    text = lines[i].strip()
    audio = fireredtts2.generate_monologue(text=text)
    # adjust temperature & topk
    # audio = fireredtts2.generate_monologue(text=text, temperature=0.8, topk=30)
    torchaudio.save(str(i) + ".wav", audio.cpu(), 24000)


# # voice clone
# for i in range(len(lines)):
#     text = lines[i].strip()

#     audio = fireredtts2.generate_monologue(
#         text=text,
#         prompt_wav=<prompt_wav_path>,
#         prompt_text=<prompt_wav_text>,
#     )
#     torchaudio.save(str(i) + ".wav", audio.cpu(), 24000)
```

## Acknowledgements

- We thank [**Moshi**](https://github.com/kyutai-labs/moshi) and [**Sesame CSM**](https://github.com/SesameAILabs/csm) for their novel dual-transformer approach. Additionally, we adapted [**Sesame CSM's**](https://github.com/SesameAILabs/csm) structure and core inference code.

- We referred to [**Qwen2.5-1.5B**](https://huggingface.co/Qwen/Qwen2.5-1.5B) text tokenizer solution.

- We referred to [**Xcodec2**](https://github.com/zhenye234/X-Codec-2.0) Vocos-based acoustic decoder.

## âš ï¸ Usage Disclaimer â—ï¸â—ï¸â—ï¸â—ï¸â—ï¸â—ï¸

- The project incorporates zero-shot voice cloning functionality; Please note that this capability is intended **solely for academic research purposes**.
- **DO NOT** use this model for **ANY illegal activities**â—ï¸â—ï¸â—ï¸â—ï¸â—ï¸â—ï¸
- The developers assume no liability for any misuse of this model.
- If you identify any instances of **abuse**, **misuse**, or **fraudulent** activities related to this project, **please report them to our team immediately.**



## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=FireRedTeam/FireRedTTS2&type=date&legend=top-left)](https://www.star-history.com/#FireRedTeam/FireRedTTS2&type=date&legend=top-left)



